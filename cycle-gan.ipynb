{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Cycle GAN for medical images segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf_slim as slim\n",
    "from collections import namedtuple\n",
    "import time\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.0002\n",
    "EPOCH_STEP=100\n",
    "LOAD_SIZE=286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_norm(input, name=\"instance_norm\"):\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        depth = input.get_shape()[3]\n",
    "        scale = tf.compat.v1.get_variable(\"scale\", [depth], initializer=tf.compat.v1.random_normal_initializer(1.0, 0.02, dtype=tf.float32))\n",
    "        offset = tf.compat.v1.get_variable(\"offset\", [depth], initializer=tf.compat.v1.constant_initializer(0.0))\n",
    "        mean, variance = tf.compat.v1.nn.moments(input, axes=[1,2], keep_dims=True)\n",
    "        epsilon = 1e-5\n",
    "        inv = tf.compat.v1.rsqrt(variance + epsilon)\n",
    "        normalized = (input-mean)*inv\n",
    "        return scale*normalized + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_, output_dim, ks=4, s=2, stddev=0.02, padding='SAME', name=\"conv2d\"):\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        return slim.conv2d(input_, output_dim, ks, s, padding=padding, activation_fn=None,\n",
    "                            weights_initializer=tf.compat.v1.truncated_normal_initializer(stddev=stddev),\n",
    "                            biases_initializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv2d(input_, output_dim, ks=4, s=2, stddev=0.02, name=\"deconv2d\"):\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        return slim.conv2d_transpose(input_, output_dim, ks, s, padding='SAME', activation_fn=None,\n",
    "                                    weights_initializer=tf.compat.v1.truncated_normal_initializer(stddev=stddev),\n",
    "                                    biases_initializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(image, options, reuse=False, name=\"discriminator\"):\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        # image is 256 x 256 x input_c_dim\n",
    "\n",
    "        h0 = lrelu(conv2d(image, options.df_dim, name='d_h0_conv'))\n",
    "        # h0 is (128 x 128 x self.df_dim)\n",
    "        h1 = lrelu(instance_norm(conv2d(h0, options.df_dim*2, name='d_h1_conv'), 'd_bn1'))\n",
    "        # h1 is (64 x 64 x self.df_dim*2)\n",
    "        h2 = lrelu(instance_norm(conv2d(h1, options.df_dim*4, name='d_h2_conv'), 'd_bn2'))\n",
    "        # h2 is (32x 32 x self.df_dim*4)\n",
    "        h3 = lrelu(instance_norm(conv2d(h2, options.df_dim*8, s=1, name='d_h3_conv'), 'd_bn3'))\n",
    "        # h3 is (32 x 32 x self.df_dim*8)\n",
    "        h4 = conv2d(h3, 1, s=1, name='d_h3_pred')\n",
    "        # h4 is (32 x 32 x 1)\n",
    "        return h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_resnet(image, options, reuse=False, name=\"generator\"):\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        # image is 256 x 256 x input_c_dim\n",
    "\n",
    "        def residule_block(x, dim, ks=3, s=1, name='res'):\n",
    "            p = int((ks - 1) / 2)\n",
    "            y = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
    "            y = instance_norm(conv2d(y, dim, ks, s, padding='VALID', name=name+'_c1'), name+'_bn1')\n",
    "            y = tf.pad(tf.nn.relu(y), [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
    "            y = instance_norm(conv2d(y, dim, ks, s, padding='VALID', name=name+'_c2'), name+'_bn2')\n",
    "            return y + x\n",
    "\n",
    "        # Justin Johnson's model from https://github.com/jcjohnson/fast-neural-style/\n",
    "        # The network with 9 blocks consists of: c7s1-32, d64, d128, R128, R128, R128,\n",
    "        # R128, R128, R128, R128, R128, R128, u64, u32, c7s1-3\n",
    "        c0 = tf.pad(image, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
    "        c1 = tf.nn.relu(instance_norm(conv2d(c0, options.gf_dim, 7, 1, padding='VALID', name='g_e1_c'), 'g_e1_bn'))\n",
    "        c2 = tf.nn.relu(instance_norm(conv2d(c1, options.gf_dim*2, 3, 2, name='g_e2_c'), 'g_e2_bn'))\n",
    "        c3 = tf.nn.relu(instance_norm(conv2d(c2, options.gf_dim*4, 3, 2, name='g_e3_c'), 'g_e3_bn'))\n",
    "        # define G network with 9 resnet blocks\n",
    "        r1 = residule_block(c3, options.gf_dim*4, name='g_r1')\n",
    "        r2 = residule_block(r1, options.gf_dim*4, name='g_r2')\n",
    "        r3 = residule_block(r2, options.gf_dim*4, name='g_r3')\n",
    "        r4 = residule_block(r3, options.gf_dim*4, name='g_r4')\n",
    "        r5 = residule_block(r4, options.gf_dim*4, name='g_r5')\n",
    "        r6 = residule_block(r5, options.gf_dim*4, name='g_r6')\n",
    "        r7 = residule_block(r6, options.gf_dim*4, name='g_r7')\n",
    "        r8 = residule_block(r7, options.gf_dim*4, name='g_r8')\n",
    "        r9 = residule_block(r8, options.gf_dim*4, name='g_r9')\n",
    "\n",
    "        d1 = deconv2d(r9, options.gf_dim*2, 3, 2, name='g_d1_dc')\n",
    "        d1 = tf.nn.relu(instance_norm(d1, 'g_d1_bn'))\n",
    "        d2 = deconv2d(d1, options.gf_dim, 3, 2, name='g_d2_dc')\n",
    "        d2 = tf.nn.relu(instance_norm(d2, 'g_d2_bn'))\n",
    "        d2 = tf.pad(d2, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
    "        pred = tf.nn.tanh(conv2d(d2, options.output_c_dim, 7, 1, padding='VALID', name='g_pred_c'))\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_criterion(in_, target):\n",
    "    return tf.reduce_mean(tf.abs(in_ - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_criterion(in_, target):\n",
    "    return tf.reduce_mean((in_-target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread as _imread\n",
    "import scipy.misc\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path, is_grayscale = False):\n",
    "    if (is_grayscale):\n",
    "        return _imread(path, flatten=True).astype(np.float)\n",
    "    else:\n",
    "        return _imread(path, pilmode='RGB').astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(image_path, load_size=286, fine_size=256, is_testing=False):\n",
    "    img_A = imread(image_path[0])\n",
    "    img_B = imread(image_path[1])\n",
    "    if not is_testing:\n",
    "        resize(img_A, (load_size, load_size))\n",
    "        resize(img_B, (load_size, load_size))\n",
    "        h1 = int(np.ceil(np.random.uniform(1e-2, load_size-fine_size)))\n",
    "        w1 = int(np.ceil(np.random.uniform(1e-2, load_size-fine_size)))\n",
    "        img_A = img_A[h1:h1+fine_size, w1:w1+fine_size]\n",
    "        img_B = img_B[h1:h1+fine_size, w1:w1+fine_size]\n",
    "\n",
    "        if np.random.random() > 0.5:\n",
    "            img_A = np.fliplr(img_A)\n",
    "            img_B = np.fliplr(img_B)\n",
    "    else:\n",
    "        img_A = scipy.misc.imresize(img_A, [fine_size, fine_size])\n",
    "        img_B = scipy.misc.imresize(img_B, [fine_size, fine_size])\n",
    "\n",
    "    img_A = img_A/127.5 - 1.\n",
    "    img_B = img_B/127.5 - 1.\n",
    "\n",
    "    img_AB = np.concatenate((img_A, img_B), axis=2)\n",
    "    # img_AB shape: (fine_size, fine_size, input_c_dim + output_c_dim)\n",
    "    return img_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cyclegan(object):\n",
    "    def __init__(self, sess):\n",
    "        self.sess = sess\n",
    "        self.batch_size = 1\n",
    "        self.image_size = 256\n",
    "        self.input_c_dim = 3\n",
    "        self.output_c_dim = 3\n",
    "        self.L1_lambda = 10.0\n",
    "        self.dataset_dir = 'med-image'\n",
    "        \n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator_resnet\n",
    "        self.criterionGAN = mae_criterion\n",
    "        OPTIONS = namedtuple('OPTIONS', 'batch_size image_size \\\n",
    "                              gf_dim df_dim output_c_dim is_training')\n",
    "        self.options = OPTIONS._make((self.batch_size, self.image_size,\n",
    "                                      64, 64, self.output_c_dim,\n",
    "                                      True))\n",
    "\n",
    "        self._build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "    def _build_model(self):\n",
    "        self.real_data = tf.compat.v1.placeholder(tf.float32,\n",
    "                                        [None, self.image_size, self.image_size,\n",
    "                                         self.input_c_dim + self.output_c_dim],\n",
    "                                        name='real_A_and_B_images')\n",
    "        self.real_A = self.real_data[:, :, :, :self.input_c_dim]\n",
    "        self.real_B = self.real_data[:, :, :, self.input_c_dim:self.input_c_dim + self.output_c_dim]\n",
    "        \n",
    "        self.fake_A = self.generator(self.real_B, self.options, True, name=\"generatorB2A\")\n",
    "        self.fake_B = self.generator(self.real_A, self.options, False, name=\"generatorA2B\")\n",
    "        self.fake_A_ = self.generator(self.fake_B, self.options, False, name=\"generatorB2A\")\n",
    "        self.fake_B_ = self.generator(self.fake_A, self.options, True, name=\"generatorA2B\")\n",
    "        \n",
    "        self.DA_fake = self.discriminator(self.fake_A, self.options, reuse=False, name=\"discriminatorA\")\n",
    "        self.DB_fake = self.discriminator(self.fake_B, self.options, reuse=False, name=\"discriminatorB\")\n",
    "        \n",
    "        self.g_loss = self.criterionGAN(self.DA_fake, tf.ones_like(self.DA_fake)) \\\n",
    "            + self.criterionGAN(self.DB_fake, tf.ones_like(self.DB_fake)) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_A, self.fake_A_) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_B, self.fake_B_)\n",
    "        self.fake_A_sample = tf.compat.v1.placeholder(tf.float32,\n",
    "                                            [None, self.image_size, self.image_size,\n",
    "                                             self.input_c_dim], name='fake_A_sample')\n",
    "        self.fake_B_sample = tf.compat.v1.placeholder(tf.float32,\n",
    "                                            [None, self.image_size, self.image_size,\n",
    "                                             self.output_c_dim], name='fake_B_sample')\n",
    "        self.DB_real = self.discriminator(self.real_B, self.options, reuse=True, name=\"discriminatorB\")\n",
    "        self.DA_real = self.discriminator(self.real_A, self.options, reuse=True, name=\"discriminatorA\")\n",
    "        self.DB_fake_sample = self.discriminator(self.fake_B_sample, self.options, reuse=True, name=\"discriminatorB\")\n",
    "        self.DA_fake_sample = self.discriminator(self.fake_A_sample, self.options, reuse=True, name=\"discriminatorA\")\n",
    "        self.db_loss_real = self.criterionGAN(self.DB_real, tf.ones_like(self.DB_real))\n",
    "        self.db_loss_fake = self.criterionGAN(self.DB_fake_sample, tf.zeros_like(self.DB_fake_sample))\n",
    "        self.db_loss = (self.db_loss_real + self.db_loss_fake) / 2\n",
    "        self.da_loss_real = self.criterionGAN(self.DA_real, tf.ones_like(self.DA_real))\n",
    "        self.da_loss_fake = self.criterionGAN(self.DA_fake_sample, tf.zeros_like(self.DA_fake_sample))\n",
    "        self.da_loss = (self.da_loss_real + self.da_loss_fake) / 2\n",
    "        self.d_loss = self.da_loss + self.db_loss\n",
    "        \n",
    "        self.g_loss_a2b_sum = tf.summary.scalar(\"g_loss_a2b\", self.g_loss_a2b)\n",
    "        self.g_sum = tf.summary.merge([self.g_loss_a2b_sum, self.g_loss_b2a_sum, self.g_loss_sum])\n",
    "        \n",
    "        t_vars = tf.compat.v1.trainable_variables()\n",
    "        self.d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "        self.g_vars = [var for var in t_vars if 'generator' in var.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beta1 is momentum term of Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "    def train(self, name='train'):\n",
    "        self.lr = tf.compat.v1.placeholder(tf.float32, None, name='learning_rate')\n",
    "        with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            self.d_optim = tf.compat.v1.train.AdamOptimizer(self.lr, beta1=0.5) \\\n",
    "            .minimize(self.d_loss, var_list=self.d_vars)\n",
    "            self.g_optim = tf.compat.v1.train.AdamOptimizer(self.lr, beta1=0.5) \\\n",
    "            .minimize(self.g_loss, var_list=self.g_vars)\n",
    "        init_op = tf.compat.v1.global_variables_initializer()\n",
    "        self.sess.run(init_op)\n",
    "        self.writer = tf.compat.v1.summary.FileWriter(\"./logs\", self.sess.graph)\n",
    "        \n",
    "        counter = 1\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(1):\n",
    "#         for epoch in range(200):\n",
    "            print(f'epoch: {epoch}')\n",
    "            dataA = glob('./datasets/{}/*.*'.format(self.dataset_dir + '/trainA'))\n",
    "            dataB = glob('./datasets/{}/*.*'.format(self.dataset_dir + '/trainB'))\n",
    "            np.random.shuffle(dataA)\n",
    "            np.random.shuffle(dataB)\n",
    "            batch_idxs = min(min(len(dataA), len(dataB)), 1e8) // self.batch_size\n",
    "            lr = LR if epoch < EPOCH_STEP else LR*(200-epoch)/(200-EPOCH_STEP)\n",
    "            \n",
    "            for idx in range(batch_idxs):\n",
    "                batch_files = list(zip(dataA[idx * self.batch_size:(idx + 1) * self.batch_size],\n",
    "                                       dataB[idx * self.batch_size:(idx + 1) * self.batch_size]))\n",
    "                batch_images = [load_train_data(batch_file, LOAD_SIZE, self.image_size) for batch_file in batch_files]\n",
    "                batch_images = np.array(batch_images).astype(np.float32)\n",
    "                \n",
    "                # Update G network and record fake outputs\n",
    "                fake_A, fake_B, _, summary_str = self.sess.run(\n",
    "                    [self.fake_A, self.fake_B, self.g_optim, self.g_sum],\n",
    "                    feed_dict={self.real_data: batch_images, self.lr: lr})\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "                [fake_A, fake_B] = self.pool([fake_A, fake_B])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'cyclegan' object has no attribute 'g_sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-386d5924b646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcyclegan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-a54c7673cf72>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;31m# Update G network and record fake outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 fake_A, fake_B, _, summary_str = self.sess.run(\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_sum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                     feed_dict={self.real_data: batch_images, self.lr: lr})\n\u001b[1;32m     36\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'cyclegan' object has no attribute 'g_sum'"
     ]
    }
   ],
   "source": [
    "tfconfig = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
    "tfconfig.gpu_options.allow_growth = True\n",
    "with tf.compat.v1.Session(config=tfconfig) as sess:\n",
    "    model = cyclegan(sess)\n",
    "    model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
