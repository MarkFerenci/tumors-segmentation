{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Cycle GAN for medical images segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf_slim as slim\n",
    "from collections import namedtuple\n",
    "import time\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.0002\n",
    "EPOCH_STEP=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_norm(input, name=\"instance_norm\"):\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        depth = input.get_shape()[3]\n",
    "        scale = tf.compat.v1.get_variable(\"scale\", [depth], initializer=tf.compat.v1.random_normal_initializer(1.0, 0.02, dtype=tf.float32))\n",
    "        offset = tf.compat.v1.get_variable(\"offset\", [depth], initializer=tf.compat.v1.constant_initializer(0.0))\n",
    "        mean, variance = tf.compat.v1.nn.moments(input, axes=[1,2], keep_dims=True)\n",
    "        epsilon = 1e-5\n",
    "        inv = tf.compat.v1.rsqrt(variance + epsilon)\n",
    "        normalized = (input-mean)*inv\n",
    "        return scale*normalized + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_, output_dim, ks=4, s=2, stddev=0.02, padding='SAME', name=\"conv2d\"):\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        return slim.conv2d(input_, output_dim, ks, s, padding=padding, activation_fn=None,\n",
    "                            weights_initializer=tf.compat.v1.truncated_normal_initializer(stddev=stddev),\n",
    "                            biases_initializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv2d(input_, output_dim, ks=4, s=2, stddev=0.02, name=\"deconv2d\"):\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        return slim.conv2d_transpose(input_, output_dim, ks, s, padding='SAME', activation_fn=None,\n",
    "                                    weights_initializer=tf.compat.v1.truncated_normal_initializer(stddev=stddev),\n",
    "                                    biases_initializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(image, options, reuse=False, name=\"discriminator\"):\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        # image is 256 x 256 x input_c_dim\n",
    "\n",
    "        h0 = lrelu(conv2d(image, options.df_dim, name='d_h0_conv'))\n",
    "        # h0 is (128 x 128 x self.df_dim)\n",
    "        h1 = lrelu(instance_norm(conv2d(h0, options.df_dim*2, name='d_h1_conv'), 'd_bn1'))\n",
    "        # h1 is (64 x 64 x self.df_dim*2)\n",
    "        h2 = lrelu(instance_norm(conv2d(h1, options.df_dim*4, name='d_h2_conv'), 'd_bn2'))\n",
    "        # h2 is (32x 32 x self.df_dim*4)\n",
    "        h3 = lrelu(instance_norm(conv2d(h2, options.df_dim*8, s=1, name='d_h3_conv'), 'd_bn3'))\n",
    "        # h3 is (32 x 32 x self.df_dim*8)\n",
    "        h4 = conv2d(h3, 1, s=1, name='d_h3_pred')\n",
    "        # h4 is (32 x 32 x 1)\n",
    "        return h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_resnet(image, options, reuse=False, name=\"generator\"):\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        # image is 256 x 256 x input_c_dim\n",
    "\n",
    "        def residule_block(x, dim, ks=3, s=1, name='res'):\n",
    "            p = int((ks - 1) / 2)\n",
    "            y = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
    "            y = instance_norm(conv2d(y, dim, ks, s, padding='VALID', name=name+'_c1'), name+'_bn1')\n",
    "            y = tf.pad(tf.nn.relu(y), [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
    "            y = instance_norm(conv2d(y, dim, ks, s, padding='VALID', name=name+'_c2'), name+'_bn2')\n",
    "            return y + x\n",
    "\n",
    "        # Justin Johnson's model from https://github.com/jcjohnson/fast-neural-style/\n",
    "        # The network with 9 blocks consists of: c7s1-32, d64, d128, R128, R128, R128,\n",
    "        # R128, R128, R128, R128, R128, R128, u64, u32, c7s1-3\n",
    "        c0 = tf.pad(image, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
    "        c1 = tf.nn.relu(instance_norm(conv2d(c0, options.gf_dim, 7, 1, padding='VALID', name='g_e1_c'), 'g_e1_bn'))\n",
    "        c2 = tf.nn.relu(instance_norm(conv2d(c1, options.gf_dim*2, 3, 2, name='g_e2_c'), 'g_e2_bn'))\n",
    "        c3 = tf.nn.relu(instance_norm(conv2d(c2, options.gf_dim*4, 3, 2, name='g_e3_c'), 'g_e3_bn'))\n",
    "        # define G network with 9 resnet blocks\n",
    "        r1 = residule_block(c3, options.gf_dim*4, name='g_r1')\n",
    "        r2 = residule_block(r1, options.gf_dim*4, name='g_r2')\n",
    "        r3 = residule_block(r2, options.gf_dim*4, name='g_r3')\n",
    "        r4 = residule_block(r3, options.gf_dim*4, name='g_r4')\n",
    "        r5 = residule_block(r4, options.gf_dim*4, name='g_r5')\n",
    "        r6 = residule_block(r5, options.gf_dim*4, name='g_r6')\n",
    "        r7 = residule_block(r6, options.gf_dim*4, name='g_r7')\n",
    "        r8 = residule_block(r7, options.gf_dim*4, name='g_r8')\n",
    "        r9 = residule_block(r8, options.gf_dim*4, name='g_r9')\n",
    "\n",
    "        d1 = deconv2d(r9, options.gf_dim*2, 3, 2, name='g_d1_dc')\n",
    "        d1 = tf.nn.relu(instance_norm(d1, 'g_d1_bn'))\n",
    "        d2 = deconv2d(d1, options.gf_dim, 3, 2, name='g_d2_dc')\n",
    "        d2 = tf.nn.relu(instance_norm(d2, 'g_d2_bn'))\n",
    "        d2 = tf.pad(d2, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
    "        pred = tf.nn.tanh(conv2d(d2, options.output_c_dim, 7, 1, padding='VALID', name='g_pred_c'))\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_criterion(in_, target):\n",
    "    return tf.reduce_mean(tf.abs(in_ - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_criterion(in_, target):\n",
    "    return tf.reduce_mean((in_-target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cyclegan(object):\n",
    "    def __init__(self, sess):\n",
    "        self.sess = sess\n",
    "        self.batch_size = 1\n",
    "        self.image_size = 256\n",
    "        self.input_c_dim = 3\n",
    "        self.output_c_dim = 3\n",
    "        self.L1_lambda = 10.0\n",
    "        self.dataset_dir = 'med-image'\n",
    "        \n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator_resnet\n",
    "        self.criterionGAN = mae_criterion\n",
    "        OPTIONS = namedtuple('OPTIONS', 'batch_size image_size \\\n",
    "                              gf_dim df_dim output_c_dim is_training')\n",
    "        self.options = OPTIONS._make((self.batch_size, self.image_size,\n",
    "                                      64, 64, self.output_c_dim,\n",
    "                                      True))\n",
    "\n",
    "        self._build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "    def _build_model(self):\n",
    "        self.real_data = tf.compat.v1.placeholder(tf.float32,\n",
    "                                        [None, self.image_size, self.image_size,\n",
    "                                         self.input_c_dim + self.output_c_dim],\n",
    "                                        name='real_A_and_B_images')\n",
    "        self.real_A = self.real_data[:, :, :, :self.input_c_dim]\n",
    "        self.real_B = self.real_data[:, :, :, self.input_c_dim:self.input_c_dim + self.output_c_dim]\n",
    "        \n",
    "        self.fake_A = self.generator(self.real_B, self.options, True, name=\"generatorB2A\")\n",
    "        self.fake_B = self.generator(self.real_A, self.options, False, name=\"generatorA2B\")\n",
    "        self.fake_A_ = self.generator(self.fake_B, self.options, False, name=\"generatorB2A\")\n",
    "        self.fake_B_ = self.generator(self.fake_A, self.options, True, name=\"generatorA2B\")\n",
    "        \n",
    "        self.DA_fake = self.discriminator(self.fake_A, self.options, reuse=False, name=\"discriminatorA\")\n",
    "        self.DB_fake = self.discriminator(self.fake_B, self.options, reuse=False, name=\"discriminatorB\")\n",
    "        \n",
    "        self.g_loss = self.criterionGAN(self.DA_fake, tf.ones_like(self.DA_fake)) \\\n",
    "            + self.criterionGAN(self.DB_fake, tf.ones_like(self.DB_fake)) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_A, self.fake_A_) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_B, self.fake_B_)\n",
    "        self.fake_A_sample = tf.compat.v1.placeholder(tf.float32,\n",
    "                                            [None, self.image_size, self.image_size,\n",
    "                                             self.input_c_dim], name='fake_A_sample')\n",
    "        self.fake_B_sample = tf.compat.v1.placeholder(tf.float32,\n",
    "                                            [None, self.image_size, self.image_size,\n",
    "                                             self.output_c_dim], name='fake_B_sample')\n",
    "        self.DB_real = self.discriminator(self.real_B, self.options, reuse=True, name=\"discriminatorB\")\n",
    "        self.DA_real = self.discriminator(self.real_A, self.options, reuse=True, name=\"discriminatorA\")\n",
    "        self.DB_fake_sample = self.discriminator(self.fake_B_sample, self.options, reuse=True, name=\"discriminatorB\")\n",
    "        self.DA_fake_sample = self.discriminator(self.fake_A_sample, self.options, reuse=True, name=\"discriminatorA\")\n",
    "        self.db_loss_real = self.criterionGAN(self.DB_real, tf.ones_like(self.DB_real))\n",
    "        self.db_loss_fake = self.criterionGAN(self.DB_fake_sample, tf.zeros_like(self.DB_fake_sample))\n",
    "        self.db_loss = (self.db_loss_real + self.db_loss_fake) / 2\n",
    "        self.da_loss_real = self.criterionGAN(self.DA_real, tf.ones_like(self.DA_real))\n",
    "        self.da_loss_fake = self.criterionGAN(self.DA_fake_sample, tf.zeros_like(self.DA_fake_sample))\n",
    "        self.da_loss = (self.da_loss_real + self.da_loss_fake) / 2\n",
    "        self.d_loss = self.da_loss + self.db_loss\n",
    "        \n",
    "        t_vars = tf.compat.v1.trainable_variables()\n",
    "        self.d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "        self.g_vars = [var for var in t_vars if 'generator' in var.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beta1 is momentum term of Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "    def train(self, name='train'):\n",
    "        self.lr = tf.compat.v1.placeholder(tf.float32, None, name='learning_rate')\n",
    "        with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            self.d_optim = tf.compat.v1.train.AdamOptimizer(self.lr, beta1=0.5) \\\n",
    "            .minimize(self.d_loss, var_list=self.d_vars)\n",
    "            self.g_optim = tf.compat.v1.train.AdamOptimizer(self.lr, beta1=0.5) \\\n",
    "            .minimize(self.g_loss, var_list=self.g_vars)\n",
    "        init_op = tf.compat.v1.global_variables_initializer()\n",
    "        self.sess.run(init_op)\n",
    "        self.writer = tf.compat.v1.summary.FileWriter(\"./logs\", self.sess.graph)\n",
    "        \n",
    "        counter = 1\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(200):\n",
    "            dataA = glob('./datasets/{}/*.*'.format(self.dataset_dir + '/trainA'))\n",
    "            dataB = glob('./datasets/{}/*.*'.format(self.dataset_dir + '/trainB'))\n",
    "            np.random.shuffle(dataA)\n",
    "            np.random.shuffle(dataB)\n",
    "            batch_idxs = min(min(len(dataA), len(dataB)), 1e8) // self.batch_size\n",
    "            lr = LR if epoch < EPOCH_STEP else LR*(200-epoch)/(200-EPOCH_STEP)\n",
    "            \n",
    "            for idx in range(batch_idxs):\n",
    "                batch_files = list(zip(dataA[idx * self.batch_size:(idx + 1) * self.batch_size],\n",
    "                                       dataB[idx * self.batch_size:(idx + 1) * self.batch_size]))\n",
    "                batch_images = [load_train_data(batch_file, args.load_size, args.fine_size) for batch_file in batch_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfconfig = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
    "tfconfig.gpu_options.allow_growth = True\n",
    "with tf.compat.v1.Session(config=tfconfig) as sess:\n",
    "    model = cyclegan(sess)\n",
    "    model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
