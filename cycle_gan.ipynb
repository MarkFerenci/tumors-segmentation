{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bacprvKX5896"
   },
   "source": [
    "# Implement Cycle GAN for medical images segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JxcXHkwo5897"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf_slim as slim\n",
    "from collections import namedtuple\n",
    "import time\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SaFjqbH85898"
   },
   "outputs": [],
   "source": [
    "LR=0.0002\n",
    "EPOCH_STEP=100\n",
    "LOAD_SIZE=286\n",
    "FINE_SIZE=256\n",
    "MAX_SIZE=50\n",
    "PRINT_FREQ=100\n",
    "SAMPLE_DIR='./sample'\n",
    "CHECKPOINT_DIR='./checkpoint'\n",
    "TEST_DIR='./test'\n",
    "SAVE_FREQ=1000\n",
    "WHICH_DIRECTION='AtoB'\n",
    "CONTINUE_TRAIN=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vG9M3_8V5898"
   },
   "outputs": [],
   "source": [
    "def instance_norm(input, name=\"instance_norm\"):\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        depth = input.get_shape()[3]\n",
    "        scale = tf.compat.v1.get_variable(\"scale\", [depth], initializer=tf.compat.v1.random_normal_initializer(1.0, 0.02, dtype=tf.float32))\n",
    "        offset = tf.compat.v1.get_variable(\"offset\", [depth], initializer=tf.compat.v1.constant_initializer(0.0))\n",
    "        mean, variance = tf.compat.v1.nn.moments(input, axes=[1,2], keep_dims=True)\n",
    "        epsilon = 1e-5\n",
    "        inv = tf.compat.v1.rsqrt(variance + epsilon)\n",
    "        normalized = (input-mean)*inv\n",
    "        return scale*normalized + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zK9pMAuC5898"
   },
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MqJ5_6Js5898"
   },
   "outputs": [],
   "source": [
    "def conv2d(input_, output_dim, ks=4, s=2, stddev=0.02, padding='SAME', name=\"conv2d\"):\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        return slim.conv2d(input_, output_dim, ks, s, padding=padding, activation_fn=None,\n",
    "                            weights_initializer=tf.compat.v1.truncated_normal_initializer(stddev=stddev),\n",
    "                            biases_initializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "I1Mgc2QX5899"
   },
   "outputs": [],
   "source": [
    "def deconv2d(input_, output_dim, ks=4, s=2, stddev=0.02, name=\"deconv2d\"):\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        return slim.conv2d_transpose(input_, output_dim, ks, s, padding='SAME', activation_fn=None,\n",
    "                                    weights_initializer=tf.compat.v1.truncated_normal_initializer(stddev=stddev),\n",
    "                                    biases_initializer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cUX-kEn-5899"
   },
   "outputs": [],
   "source": [
    "def discriminator(image, options, reuse=False, name=\"discriminator\"):\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        # image is 256 x 256 x input_c_dim\n",
    "\n",
    "        h0 = lrelu(conv2d(image, options.df_dim, name='d_h0_conv'))\n",
    "        # h0 is (128 x 128 x self.df_dim)\n",
    "        h1 = lrelu(instance_norm(conv2d(h0, options.df_dim*2, name='d_h1_conv'), 'd_bn1'))\n",
    "        # h1 is (64 x 64 x self.df_dim*2)\n",
    "        h2 = lrelu(instance_norm(conv2d(h1, options.df_dim*4, name='d_h2_conv'), 'd_bn2'))\n",
    "        # h2 is (32x 32 x self.df_dim*4)\n",
    "        h3 = lrelu(instance_norm(conv2d(h2, options.df_dim*8, s=1, name='d_h3_conv'), 'd_bn3'))\n",
    "        # h3 is (32 x 32 x self.df_dim*8)\n",
    "        h4 = conv2d(h3, 1, s=1, name='d_h3_pred')\n",
    "        # h4 is (32 x 32 x 1)\n",
    "        return h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DOEB3WsA5899"
   },
   "outputs": [],
   "source": [
    "def generator_resnet(image, options, reuse=False, name=\"generator\"):\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "        # image is 256 x 256 x input_c_dim\n",
    "\n",
    "        def residule_block(x, dim, ks=3, s=1, name='res'):\n",
    "            p = int((ks - 1) / 2)\n",
    "            y = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
    "            y = instance_norm(conv2d(y, dim, ks, s, padding='VALID', name=name+'_c1'), name+'_bn1')\n",
    "            y = tf.pad(tf.nn.relu(y), [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
    "            y = instance_norm(conv2d(y, dim, ks, s, padding='VALID', name=name+'_c2'), name+'_bn2')\n",
    "            return y + x\n",
    "\n",
    "        # Justin Johnson's model from https://github.com/jcjohnson/fast-neural-style/\n",
    "        # The network with 9 blocks consists of: c7s1-32, d64, d128, R128, R128, R128,\n",
    "        # R128, R128, R128, R128, R128, R128, u64, u32, c7s1-3\n",
    "        c0 = tf.pad(image, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
    "        c1 = tf.nn.relu(instance_norm(conv2d(c0, options.gf_dim, 7, 1, padding='VALID', name='g_e1_c'), 'g_e1_bn'))\n",
    "        c2 = tf.nn.relu(instance_norm(conv2d(c1, options.gf_dim*2, 3, 2, name='g_e2_c'), 'g_e2_bn'))\n",
    "        c3 = tf.nn.relu(instance_norm(conv2d(c2, options.gf_dim*4, 3, 2, name='g_e3_c'), 'g_e3_bn'))\n",
    "        # define G network with 9 resnet blocks\n",
    "        r1 = residule_block(c3, options.gf_dim*4, name='g_r1')\n",
    "        r2 = residule_block(r1, options.gf_dim*4, name='g_r2')\n",
    "        r3 = residule_block(r2, options.gf_dim*4, name='g_r3')\n",
    "        r4 = residule_block(r3, options.gf_dim*4, name='g_r4')\n",
    "        r5 = residule_block(r4, options.gf_dim*4, name='g_r5')\n",
    "        r6 = residule_block(r5, options.gf_dim*4, name='g_r6')\n",
    "        r7 = residule_block(r6, options.gf_dim*4, name='g_r7')\n",
    "        r8 = residule_block(r7, options.gf_dim*4, name='g_r8')\n",
    "        r9 = residule_block(r8, options.gf_dim*4, name='g_r9')\n",
    "\n",
    "        d1 = deconv2d(r9, options.gf_dim*2, 3, 2, name='g_d1_dc')\n",
    "        d1 = tf.nn.relu(instance_norm(d1, 'g_d1_bn'))\n",
    "        d2 = deconv2d(d1, options.gf_dim, 3, 2, name='g_d2_dc')\n",
    "        d2 = tf.nn.relu(instance_norm(d2, 'g_d2_bn'))\n",
    "        d2 = tf.pad(d2, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
    "        pred = tf.nn.tanh(conv2d(d2, options.output_c_dim, 7, 1, padding='VALID', name='g_pred_c'))\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xQR938tE5899"
   },
   "outputs": [],
   "source": [
    "def abs_criterion(in_, target):\n",
    "    return tf.reduce_mean(tf.abs(in_ - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t0qGLBXR5899"
   },
   "outputs": [],
   "source": [
    "def mae_criterion(in_, target):\n",
    "    return tf.reduce_mean((in_-target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "o63Ssqyy5899"
   },
   "outputs": [],
   "source": [
    "from imageio import imread as _imread\n",
    "from imageio import imwrite\n",
    "import scipy.misc\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mJ7C6q_h0RY5"
   },
   "outputs": [],
   "source": [
    "def inverse_transform(images):\n",
    "    return (images+1.)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3wjgkvJW2_hC"
   },
   "outputs": [],
   "source": [
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BjsBbSqE1SMg"
   },
   "outputs": [],
   "source": [
    "def imsave(images, size, path):\n",
    "    return imwrite(path, merge(images, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "u_yT_brp0K5q"
   },
   "outputs": [],
   "source": [
    "def save_images(images, size, image_path):\n",
    "    imsave(inverse_transform(images), size, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rZ0LlEXN5899"
   },
   "outputs": [],
   "source": [
    "def imread(path, is_grayscale = False):\n",
    "    if (is_grayscale):\n",
    "        return _imread(path, flatten=True).astype(np.float)\n",
    "    else:\n",
    "        return _imread(path, pilmode='RGB').astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NttD9quN5899"
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lFRu28W-589-"
   },
   "outputs": [],
   "source": [
    "class ImagePool(object):\n",
    "    def __init__(self, maxsize=50):\n",
    "        self.maxsize = maxsize\n",
    "        self.num_img = 0\n",
    "        self.images = []\n",
    "\n",
    "    def __call__(self, image):\n",
    "        if self.maxsize <= 0:\n",
    "            return image\n",
    "        if self.num_img < self.maxsize:\n",
    "            self.images.append(image)\n",
    "            self.num_img += 1\n",
    "            return image\n",
    "        if np.random.rand() > 0.5:\n",
    "            idx = int(np.random.rand()*self.maxsize)\n",
    "            tmp1 = copy.copy(self.images[idx])[0]\n",
    "            self.images[idx][0] = image[0]\n",
    "            idx = int(np.random.rand()*self.maxsize)\n",
    "            tmp2 = copy.copy(self.images[idx])[1]\n",
    "            self.images[idx][1] = image[1]\n",
    "            return [tmp1, tmp2]\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zzXKokL4589-"
   },
   "outputs": [],
   "source": [
    "def load_train_data(image_path, load_size=286, fine_size=256, is_testing=False):\n",
    "    img_A = imread(image_path[0])\n",
    "    img_B = imread(image_path[1])\n",
    "    if not is_testing:\n",
    "        img_A = resize(img_A, (load_size, load_size))\n",
    "        img_B = resize(img_B, (load_size, load_size))\n",
    "        h1 = int(np.ceil(np.random.uniform(1e-2, load_size-fine_size)))\n",
    "        w1 = int(np.ceil(np.random.uniform(1e-2, load_size-fine_size)))\n",
    "        img_A = img_A[h1:h1+fine_size, w1:w1+fine_size]\n",
    "        img_B = img_B[h1:h1+fine_size, w1:w1+fine_size]\n",
    "\n",
    "        if np.random.random() > 0.5:\n",
    "            img_A = np.fliplr(img_A)\n",
    "            img_B = np.fliplr(img_B)\n",
    "    else:\n",
    "        img_A = resize(img_A, (fine_size, fine_size))\n",
    "        img_B = resize(img_B, (fine_size, fine_size))\n",
    "\n",
    "    img_A = img_A/127.5 - 1.\n",
    "    img_B = img_B/127.5 - 1.\n",
    "\n",
    "    img_AB = np.concatenate((img_A, img_B), axis=2)\n",
    "    # img_AB shape: (fine_size, fine_size, input_c_dim + output_c_dim)\n",
    "    return img_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "habSRNdhawg1"
   },
   "outputs": [],
   "source": [
    "def load_test_data(image_path, fine_size=256):\n",
    "    img = imread(image_path)\n",
    "    img = resize(img, (fine_size, fine_size))\n",
    "    img = img/127.5 - 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JL88EgmR589-"
   },
   "outputs": [],
   "source": [
    "class cyclegan(object):\n",
    "    def __init__(self, sess):\n",
    "        self.sess = sess\n",
    "        self.batch_size = 1\n",
    "        self.image_size = FINE_SIZE\n",
    "        self.input_c_dim = 3\n",
    "        self.output_c_dim = 3\n",
    "        self.L1_lambda = 10.0\n",
    "        self.dataset_dir = 'med-image'\n",
    "        \n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator_resnet\n",
    "        self.criterionGAN = mae_criterion\n",
    "        OPTIONS = namedtuple('OPTIONS', 'batch_size image_size \\\n",
    "                              gf_dim df_dim output_c_dim is_training')\n",
    "        self.options = OPTIONS._make((self.batch_size, self.image_size,\n",
    "                                      64, 64, self.output_c_dim,\n",
    "                                      True))\n",
    "\n",
    "        self._build_model()\n",
    "        self.saver = tf.compat.v1.train.Saver()\n",
    "        self.pool = ImagePool(MAX_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TgyADhpEUKlM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `tf.compat.v1.train.Saver().save` not found.\n"
     ]
    }
   ],
   "source": [
    "?tf.compat.v1.train.Saver().save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "f9cW3Xpf589-"
   },
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "    def _build_model(self):\n",
    "        self.real_data = tf.compat.v1.placeholder(tf.float32,\n",
    "                                        [None, self.image_size, self.image_size,\n",
    "                                         self.input_c_dim + self.output_c_dim],\n",
    "                                        name='real_A_and_B_images')\n",
    "        self.real_A = self.real_data[:, :, :, :self.input_c_dim]\n",
    "        self.real_B = self.real_data[:, :, :, self.input_c_dim:self.input_c_dim + self.output_c_dim]\n",
    "        \n",
    "        self.fake_A = self.generator(self.real_B, self.options, True, name=\"generatorB2A\")\n",
    "        self.fake_B = self.generator(self.real_A, self.options, False, name=\"generatorA2B\")\n",
    "        self.fake_A_ = self.generator(self.fake_B, self.options, False, name=\"generatorB2A\")\n",
    "        self.fake_B_ = self.generator(self.fake_A, self.options, True, name=\"generatorA2B\")\n",
    "        \n",
    "        self.DA_fake = self.discriminator(self.fake_A, self.options, reuse=False, name=\"discriminatorA\")\n",
    "        self.DB_fake = self.discriminator(self.fake_B, self.options, reuse=False, name=\"discriminatorB\")\n",
    "        \n",
    "        self.g_loss_a2b = self.criterionGAN(self.DB_fake, tf.ones_like(self.DB_fake)) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_A, self.fake_A_) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_B, self.fake_B_)\n",
    "        self.g_loss_b2a = self.criterionGAN(self.DA_fake, tf.ones_like(self.DA_fake)) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_A, self.fake_A_) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_B, self.fake_B_)\n",
    "        \n",
    "        self.g_loss = self.criterionGAN(self.DA_fake, tf.ones_like(self.DA_fake)) \\\n",
    "            + self.criterionGAN(self.DB_fake, tf.ones_like(self.DB_fake)) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_A, self.fake_A_) \\\n",
    "            + self.L1_lambda * abs_criterion(self.real_B, self.fake_B_)\n",
    "        self.fake_A_sample = tf.compat.v1.placeholder(tf.float32,\n",
    "                                            [None, self.image_size, self.image_size,\n",
    "                                             self.input_c_dim], name='fake_A_sample')\n",
    "        self.fake_B_sample = tf.compat.v1.placeholder(tf.float32,\n",
    "                                            [None, self.image_size, self.image_size,\n",
    "                                             self.output_c_dim], name='fake_B_sample')\n",
    "        self.DB_real = self.discriminator(self.real_B, self.options, reuse=True, name=\"discriminatorB\")\n",
    "        self.DA_real = self.discriminator(self.real_A, self.options, reuse=True, name=\"discriminatorA\")\n",
    "        self.DB_fake_sample = self.discriminator(self.fake_B_sample, self.options, reuse=True, name=\"discriminatorB\")\n",
    "        self.DA_fake_sample = self.discriminator(self.fake_A_sample, self.options, reuse=True, name=\"discriminatorA\")\n",
    "        self.db_loss_real = self.criterionGAN(self.DB_real, tf.ones_like(self.DB_real))\n",
    "        self.db_loss_fake = self.criterionGAN(self.DB_fake_sample, tf.zeros_like(self.DB_fake_sample))\n",
    "        self.db_loss = (self.db_loss_real + self.db_loss_fake) / 2\n",
    "        self.da_loss_real = self.criterionGAN(self.DA_real, tf.ones_like(self.DA_real))\n",
    "        self.da_loss_fake = self.criterionGAN(self.DA_fake_sample, tf.zeros_like(self.DA_fake_sample))\n",
    "        self.da_loss = (self.da_loss_real + self.da_loss_fake) / 2\n",
    "        self.d_loss = self.da_loss + self.db_loss\n",
    "        \n",
    "        self.g_loss_a2b_sum = tf.compat.v1.summary.scalar(\"g_loss_a2b\", self.g_loss_a2b)\n",
    "        self.g_loss_b2a_sum = tf.compat.v1.summary.scalar(\"g_loss_b2a\", self.g_loss_b2a)\n",
    "        self.g_loss_sum = tf.compat.v1.summary.scalar(\"g_loss\", self.g_loss)\n",
    "\n",
    "        self.g_sum = tf.compat.v1.summary.merge([self.g_loss_a2b_sum, self.g_loss_b2a_sum, self.g_loss_sum])\n",
    "        \n",
    "        self.da_loss_sum = tf.compat.v1.summary.scalar(\"da_loss\", self.da_loss)\n",
    "        self.db_loss_sum = tf.compat.v1.summary.scalar(\"db_loss\", self.db_loss)\n",
    "        self.d_loss_sum = tf.compat.v1.summary.scalar(\"d_loss\", self.d_loss)\n",
    "        self.da_loss_real_sum = tf.compat.v1.summary.scalar(\"da_loss_real\", self.da_loss_real)\n",
    "        self.db_loss_real_sum = tf.compat.v1.summary.scalar(\"db_loss_real\", self.db_loss_real)\n",
    "        self.da_loss_fake_sum = tf.compat.v1.summary.scalar(\"da_loss_fake\", self.da_loss_fake)\n",
    "        self.db_loss_fake_sum = tf.compat.v1.summary.scalar(\"db_loss_fake\", self.db_loss_fake)\n",
    "        self.d_sum = tf.compat.v1.summary.merge(\n",
    "            [self.da_loss_sum, self.da_loss_real_sum, self.da_loss_fake_sum,\n",
    "             self.db_loss_sum, self.db_loss_real_sum, self.db_loss_fake_sum,\n",
    "             self.d_loss_sum]\n",
    "        )\n",
    "\n",
    "        self.test_A = tf.compat.v1.placeholder(tf.float32,\n",
    "                                     [None, self.image_size, self.image_size,\n",
    "                                      self.input_c_dim], name='test_A')\n",
    "        self.test_B = tf.compat.v1.placeholder(tf.float32,\n",
    "                                     [None, self.image_size, self.image_size,\n",
    "                                      self.output_c_dim], name='test_B')\n",
    "        self.testA = self.generator(self.test_B, self.options, True, name=\"generatorB2A\")\n",
    "        self.testB = self.generator(self.test_A, self.options, True, name=\"generatorA2B\")\n",
    "        \n",
    "        t_vars = tf.compat.v1.trainable_variables()\n",
    "        self.d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "        self.g_vars = [var for var in t_vars if 'generator' in var.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHY0F8UB589_"
   },
   "source": [
    "beta1 is momentum term of Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SuokKRRECOt2"
   },
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "  def sample_model(self, sample_dir, epoch, idx):\n",
    "      dataA = glob('./datasets/{}/*.*'.format(self.dataset_dir + '/testA'))\n",
    "      dataB = glob('./datasets/{}/*.*'.format(self.dataset_dir + '/testB'))\n",
    "      np.random.shuffle(dataA)\n",
    "      np.random.shuffle(dataB)\n",
    "      batch_files = list(zip(dataA[:self.batch_size], dataB[:self.batch_size]))\n",
    "      sample_images = [load_train_data(batch_file, is_testing=True) for batch_file in batch_files]\n",
    "      sample_images = np.array(sample_images).astype(np.float32)\n",
    "\n",
    "      fake_A, fake_B = self.sess.run(\n",
    "          [self.fake_A, self.fake_B],\n",
    "          feed_dict={self.real_data: sample_images}\n",
    "      )\n",
    "      save_images(fake_A, [self.batch_size, 1],\n",
    "                  './{}/A_{:02d}_{:04d}.jpg'.format(sample_dir, epoch, idx))\n",
    "      save_images(fake_B, [self.batch_size, 1],\n",
    "                  './{}/B_{:02d}_{:04d}.jpg'.format(sample_dir, epoch, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nVDLHvLPC6Kc"
   },
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "  def save(self, checkpoint_dir, step):\n",
    "          model_name = \"cyclegan.model\"\n",
    "          model_dir = \"%s_%s\" % (self.dataset_dir, self.image_size)\n",
    "          checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "          if not os.path.exists(checkpoint_dir):\n",
    "              os.makedirs(checkpoint_dir)\n",
    "\n",
    "          self.saver.save(self.sess,\n",
    "                          os.path.join(checkpoint_dir, model_name),\n",
    "                          global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "9KquSN3dN9Fk"
   },
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "  def load(self, checkpoint_dir):\n",
    "        print(\" [*] Reading checkpoint...\")\n",
    "\n",
    "        model_dir = \"%s_%s\" % (self.dataset_dir, self.image_size)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            print(f'check: {ckpt_name}')\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vPwYFFpv589_"
   },
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "    def train(self, name='train'):\n",
    "        self.lr = tf.compat.v1.placeholder(tf.float32, None, name='learning_rate')\n",
    "        with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            self.d_optim = tf.compat.v1.train.AdamOptimizer(self.lr, beta1=0.5) \\\n",
    "            .minimize(self.d_loss, var_list=self.d_vars)\n",
    "            self.g_optim = tf.compat.v1.train.AdamOptimizer(self.lr, beta1=0.5) \\\n",
    "            .minimize(self.g_loss, var_list=self.g_vars)\n",
    "        init_op = tf.compat.v1.global_variables_initializer()\n",
    "        self.sess.run(init_op)\n",
    "        self.writer = tf.compat.v1.summary.FileWriter(\"./logs\", self.sess.graph)\n",
    "        \n",
    "        counter = 1\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if CONTINUE_TRAIN:\n",
    "            if self.load(CHECKPOINT_DIR):\n",
    "                print(\" [*] Load SUCCESS\")\n",
    "            else:\n",
    "                print(\" [!] Load failed...\")\n",
    "\n",
    "        for epoch in range(1):\n",
    "            dataA = glob('./datasets/{}/*.*'.format(self.dataset_dir + '/trainA'))[100:150]\n",
    "            dataB = glob('./datasets/{}/*.*'.format(self.dataset_dir + '/trainB'))[100:150]\n",
    "            np.random.shuffle(dataA)\n",
    "            np.random.shuffle(dataB)\n",
    "            batch_idxs = min(min(len(dataA), len(dataB)), 1e8) // self.batch_size\n",
    "            lr = LR if epoch < EPOCH_STEP else LR*(200-epoch)/(200-EPOCH_STEP)\n",
    "            \n",
    "            for idx in range(batch_idxs):\n",
    "                batch_files = list(zip(dataA[idx * self.batch_size:(idx + 1) * self.batch_size],\n",
    "                                       dataB[idx * self.batch_size:(idx + 1) * self.batch_size]))\n",
    "                batch_images = [load_train_data(batch_file, LOAD_SIZE, self.image_size) for batch_file in batch_files]\n",
    "                batch_images = np.array(batch_images).astype(np.float32)\n",
    "                \n",
    "                # Update G network and record fake outputs\n",
    "                fake_A, fake_B, _, summary_str = self.sess.run(\n",
    "                    [self.fake_A, self.fake_B, self.g_optim, self.g_sum],\n",
    "                    feed_dict={self.real_data: batch_images, self.lr: lr})\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "                [fake_A, fake_B] = self.pool([fake_A, fake_B])\n",
    "                # Update D network\n",
    "                _, summary_str = self.sess.run(\n",
    "                    [self.d_optim, self.d_sum],\n",
    "                    feed_dict={self.real_data: batch_images,\n",
    "                               self.fake_A_sample: fake_A,\n",
    "                               self.fake_B_sample: fake_B,\n",
    "                               self.lr: lr})\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                counter += 1\n",
    "                print((\"Epoch: [%2d] [%4d/%4d] time: %4.4f\" % (\n",
    "                    epoch, idx, batch_idxs, time.time() - start_time)))\n",
    "                \n",
    "                if np.mod(counter, PRINT_FREQ) == 1:\n",
    "                    self.sample_model(SAMPLE_DIR, epoch, idx)\n",
    "\n",
    "                # if np.mod(counter, args.save_freq) == 2:\n",
    "                self.save(CHECKPOINT_DIR, counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1XeerVhrKsua"
   },
   "outputs": [],
   "source": [
    "class cyclegan(cyclegan):\n",
    "  def test(self):\n",
    "    init_op = tf.compat.v1.global_variables_initializer()\n",
    "    self.sess.run(init_op)\n",
    "    sample_files = glob('./datasets/{}/*.*'.format(self.dataset_dir + '/testA'))\n",
    "\n",
    "    if self.load(CHECKPOINT_DIR):\n",
    "        print(\" [*] Load SUCCESS\")\n",
    "    else:\n",
    "        print(\" [!] Load failed...\")\n",
    "\n",
    "    index_path = os.path.join(TEST_DIR, '{0}_index.html'.format(WHICH_DIRECTION))\n",
    "    index = open(index_path, \"w\")\n",
    "    index.write(\"<html><body><table><tr>\")\n",
    "    index.write(\"<th>name</th><th>input</th><th>output</th></tr>\")\n",
    "\n",
    "    in_var, out_var = (self.test_A, self.testB)\n",
    "\n",
    "    for sample_file in sample_files:\n",
    "            print('Processing image: ' + sample_file)\n",
    "            sample_image = [load_test_data(sample_file, FINE_SIZE)]\n",
    "            sample_image = np.array(sample_image).astype(np.float32)\n",
    "            image_path = os.path.join(TEST_DIR,\n",
    "                                      '{0}_{1}'.format(WHICH_DIRECTION, os.path.basename(sample_file)))\n",
    "            fake_img = self.sess.run(out_var, feed_dict={in_var: sample_image})\n",
    "            save_images(fake_img, [1, 1], image_path)\n",
    "            index.write(\"<td>%s</td>\" % os.path.basename(image_path))\n",
    "            index.write(\"<td><img src='%s'></td>\" % (sample_file if os.path.isabs(sample_file) else (\n",
    "                '..' + os.path.sep + sample_file)))\n",
    "            index.write(\"<td><img src='%s'></td>\" % (image_path if os.path.isabs(image_path) else (\n",
    "                '..' + os.path.sep + image_path)))\n",
    "            index.write(\"</tr>\")\n",
    "    index.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rZ78PihB589_",
    "outputId": "0decd94b-33cf-43bd-c970-6cde11c5fe59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/linuxfan/cvut/bpr/venv/lib/python3.8/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-bff02ef63efb>:4: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      " [*] Reading checkpoint...\n",
      "check: cyclegan.model-51\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/med-image_256/cyclegan.model-51\n",
      " [*] Load SUCCESS\n",
      "Epoch: [ 0] [   0/  50] time: 13.5681\n",
      "Epoch: [ 0] [   1/  50] time: 24.2483\n",
      "Epoch: [ 0] [   2/  50] time: 34.3776\n",
      "Epoch: [ 0] [   3/  50] time: 44.4823\n",
      "Epoch: [ 0] [   4/  50] time: 54.4077\n",
      "Epoch: [ 0] [   5/  50] time: 64.2137\n",
      "WARNING:tensorflow:From /home/linuxfan/cvut/bpr/venv/lib/python3.8/site-packages/tensorflow/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: [ 0] [   6/  50] time: 74.1341\n",
      "Epoch: [ 0] [   7/  50] time: 84.0363\n",
      "Epoch: [ 0] [   8/  50] time: 93.8088\n",
      "Epoch: [ 0] [   9/  50] time: 103.7435\n",
      "Epoch: [ 0] [  10/  50] time: 113.6216\n",
      "Epoch: [ 0] [  11/  50] time: 123.3981\n",
      "Epoch: [ 0] [  12/  50] time: 133.5181\n",
      "Epoch: [ 0] [  13/  50] time: 143.5890\n",
      "Epoch: [ 0] [  14/  50] time: 153.4087\n",
      "Epoch: [ 0] [  15/  50] time: 162.0624\n",
      "Epoch: [ 0] [  16/  50] time: 170.1721\n",
      "Epoch: [ 0] [  17/  50] time: 178.2154\n",
      "Epoch: [ 0] [  18/  50] time: 186.2211\n",
      "Epoch: [ 0] [  19/  50] time: 194.2654\n",
      "Epoch: [ 0] [  20/  50] time: 202.2583\n",
      "Epoch: [ 0] [  21/  50] time: 210.3915\n",
      "Epoch: [ 0] [  22/  50] time: 218.5383\n",
      "Epoch: [ 0] [  23/  50] time: 226.5618\n",
      "Epoch: [ 0] [  24/  50] time: 234.4905\n",
      "Epoch: [ 0] [  25/  50] time: 242.5291\n",
      "Epoch: [ 0] [  26/  50] time: 250.6816\n",
      "Epoch: [ 0] [  27/  50] time: 258.7706\n",
      "Epoch: [ 0] [  28/  50] time: 266.7455\n",
      "Epoch: [ 0] [  29/  50] time: 274.7789\n",
      "Epoch: [ 0] [  30/  50] time: 282.8388\n",
      "Epoch: [ 0] [  31/  50] time: 291.1574\n",
      "Epoch: [ 0] [  32/  50] time: 299.2515\n",
      "Epoch: [ 0] [  33/  50] time: 307.2408\n",
      "Epoch: [ 0] [  34/  50] time: 315.2614\n",
      "Epoch: [ 0] [  35/  50] time: 323.4453\n",
      "Epoch: [ 0] [  36/  50] time: 331.6788\n",
      "Epoch: [ 0] [  37/  50] time: 339.7970\n",
      "Epoch: [ 0] [  38/  50] time: 347.7997\n",
      "Epoch: [ 0] [  39/  50] time: 355.7980\n",
      "Epoch: [ 0] [  40/  50] time: 363.7487\n",
      "Epoch: [ 0] [  41/  50] time: 371.9360\n",
      "Epoch: [ 0] [  42/  50] time: 379.8937\n",
      "Epoch: [ 0] [  43/  50] time: 387.9066\n",
      "Epoch: [ 0] [  44/  50] time: 396.1870\n",
      "Epoch: [ 0] [  45/  50] time: 404.1644\n",
      "Epoch: [ 0] [  46/  50] time: 412.5152\n",
      "Epoch: [ 0] [  47/  50] time: 420.8489\n",
      "Epoch: [ 0] [  48/  50] time: 429.1236\n",
      "Epoch: [ 0] [  49/  50] time: 437.2537\n",
      " [*] Reading checkpoint...\n",
      "check: cyclegan.model-51\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/med-image_256/cyclegan.model-51\n",
      " [*] Load SUCCESS\n",
      "Processing image: ./datasets/med-image/testA/A_TB_1312_112027.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1334_90284.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1373_103148.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1336_90284.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1319_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1315_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1310_107747.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1351_100416.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1327_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1377_105653.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1318_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1330_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1388_107747.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1311_107747.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1324_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1343_93825.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1366_101020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1381_106494.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1346_97609.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1328_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1355_100820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1397_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1380_106494.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1331_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1369_101384.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1338_90284.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1348_97609.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1345_97609.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1323_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1333_90284.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1329_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1341_92897.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1335_90284.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1371_102075.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1396_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1375_103148.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1326_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1339_90284.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1356_100820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1362_101020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1363_101020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1394_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1364_101020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1358_100820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1337_90284.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1367_101384.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1390_108479.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1387_107747.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1360_100820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1349_97609.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1395_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1322_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1389_107747.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1385_106494.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1340_92897.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1332_90284.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1398_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1320_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1309_107747.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1379_106494.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1384_106494.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1382_106494.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1376_103148.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1342_93825.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1400_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1354_100416.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1391_108479.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1350_97609.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1370_102075.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1368_101384.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1357_100820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1314_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1353_100416.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1352_100416.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1317_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1359_100820.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1316_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1365_101020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1347_97609.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1378_105653.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1383_106494.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1344_93825.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1374_103148.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1372_102075.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1361_101020.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1313_112027.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1393_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1386_107747.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1321_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1325_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1399_88670.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: ./datasets/med-image/testA/A_TB_1392_112105.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "tfconfig = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
    "tfconfig.gpu_options.allow_growth = True\n",
    "with tf.compat.v1.Session(config=tfconfig) as sess:\n",
    "    model = cyclegan(sess)\n",
    "    model.train()\n",
    "    model.test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cycle-gan.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
